# Visualizing Gradient Optimizers with Simple Functions
![Gradient Optimizers](/images/gradientdescent.gif)
![Gradient Functions](/images/functions.gif)

## Purpose
This notebook shows how a series of gradient optimizers work and converge to the minima of a simple loss function, and how it can be used to train machine learning models. The purpose of this notebook is to educate as well as allow for users to experiment with their own functions, and ultimately gain some insight on the performance and the behavior of these optimizers.

## Using the notebook
The notebook contains information about each optimizer and builds each from scratch with simple mathematical operations. Running the entire notebook generates the plot shown in the screenshot above, which users can interact with to change the number of iteration steps, which optimizers to toggle, and change the angle on the 3D graph.

The notebook was built with the following packages:
1. numpy (1.18.5)
2. matplotlib (3.3.2)
3. plotly (4.8.2)
